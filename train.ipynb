{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "200e8ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "import mrcnn\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.model import MaskRCNN\n",
    "import numpy as np\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "import colorsys\n",
    "import argparse\n",
    "import imutils\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from keras.models import load_model\n",
    "\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e98a134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.5\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                17\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               10\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mamogram_config\n",
      "NUM_CLASSES                    5\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                1000\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MamogramConfig(Config):\n",
    "    # give the configuration a recognizable name\n",
    "    NAME = \"mamogram_config\"\n",
    " \n",
    "    # set the number of GPUs to use along with the number of images\n",
    "    # per GPU\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    " \n",
    "    # number of classes (we would normally add +1 for the background)\n",
    "     # birads1 + birads2 + birads4 + birads5 + BG\n",
    "    NUM_CLASSES = 4+1\n",
    "    \n",
    "    # Learning rate\n",
    "    LEARNING_RATE=0.001\n",
    "    \n",
    "    # Skip detections with < 90% confidence\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    \n",
    "    # setting Max ground truth instances\n",
    "    MAX_GT_INSTANCES=10\n",
    "\n",
    "\n",
    "config = MamogramConfig()\n",
    "\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "232c278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MamoDataset(Dataset):\n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, dataset_dir):\n",
    "        \n",
    "        # Add classes. We have only one class to add.\n",
    "        self.add_class(\"dataset\", 1, \"1\")\n",
    "        self.add_class(\"dataset\", 2, \"2\")\n",
    "        self.add_class(\"dataset\", 4, \"4\")\n",
    "        self.add_class(\"dataset\", 5, \"5\")\n",
    "        \n",
    "        # define data locations for images and annotations\n",
    "        images_dir = dataset_dir + '/images/'\n",
    "        annotations_dir = dataset_dir + '/annots/'\n",
    "        \n",
    "        # Iterate through all files in the folder to \n",
    "        #add class, images and annotaions\n",
    "        for filename in listdir(images_dir):\n",
    "            \n",
    "            # extract image id\n",
    "            image_id = filename[:-4]\n",
    "            \n",
    "            # setting image file\n",
    "            img_path = images_dir + filename\n",
    "            \n",
    "            # setting annotations file\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            \n",
    "            # adding images and annotations to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "            # extract bounding boxes from an annotation file\n",
    "    def extract_boxes(self, filename):\n",
    "\n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for object in root.findall('.//object'):\n",
    "                box = object.find('bndbox')\n",
    "                label = object.find('name').text\n",
    "                xmin = int(box.find('xmin').text)\n",
    "                ymin = int(box.find('ymin').text)\n",
    "                xmax = int(box.find('xmax').text)\n",
    "                ymax = int(box.find('ymax').text)\n",
    "                coors = [xmin, ymin, xmax, ymax, label]\n",
    "                boxes.append(coors)\n",
    "\n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        return boxes, width, height\n",
    "\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "\n",
    "        # define anntation  file location\n",
    "        path = info['annotation']\n",
    "\n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "\n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(str(box[-1]))\n",
    "            print(box[-1])\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "\n",
    "    # load an image reference\n",
    "    \"\"\"Return the path of the image.\"\"\"\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        print(info)\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c10a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 639\n",
      "Train: 639\n"
     ]
    }
   ],
   "source": [
    "# prepare train set\n",
    "train_set = MamoDataset()\n",
    "train_set.load_dataset('./dataset')\n",
    "train_set.prepare()\n",
    "print('Train: %d'% len(train_set.image_ids))\n",
    "\n",
    "test_set = MamoDataset()\n",
    "test_set.load_dataset('./dataset')\n",
    "test_set.prepare()\n",
    "print('Train: %d'% len(test_set.image_ids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8658fe76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Mask R-CNN model...\n",
      "WARNING:tensorflow:From /home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1154: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1188: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Mask R-CNN model...\")\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir='./pretrained/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5542181c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-13 03:47:28.686335: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2022-03-13 03:47:28.705190: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2899885000 Hz\n",
      "2022-03-13 03:47:28.705474: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x55df6053c3e0 executing computations on platform Host. Devices:\n",
      "2022-03-13 03:47:28.705484: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\n"
     ]
    }
   ],
   "source": [
    "#load the weights for COCO\n",
    "model.load_weights('./pretrained/mask_rcnn_coco.h5', \n",
    "                   by_name=True, \n",
    "                   exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8b497f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: ./pretrained/mamogram_config20220313T0347/mask_rcnn_mamogram_config_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "WARNING:tensorflow:From /home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/home/shakhzodbek/anaconda3/envs/mrcnn/lib/python3.7/site-packages/keras/engine/training.py:1987: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "5\n",
      "4\n",
      "Epoch 1/5\n",
      "2\n",
      "2\n",
      "22\n",
      "\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "24\n",
      "\n",
      "2\n",
      "2\n",
      "2\n",
      "42\n",
      "\n",
      "22\n",
      "\n",
      "4\n",
      "2\n",
      "42\n",
      "\n",
      "52\n",
      "\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "22\n",
      "2\n",
      "\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "54\n",
      "\n",
      "5\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "24\n",
      "\n",
      "54\n",
      "\n",
      "4\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "24\n",
      "\n",
      "2\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "42\n",
      "\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "44\n",
      "\n",
      "24\n",
      "\n",
      "42\n",
      "2\n",
      "\n",
      "2\n",
      "44\n",
      "\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "22\n",
      "\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "4\n",
      "45\n",
      "\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "52\n",
      "\n",
      "2\n",
      "2\n",
      "5\n",
      "52\n",
      "\n",
      "22\n",
      "\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "model.train(train_set,test_set, learning_rate=config.LEARNING_RATE, epochs=5, layers='heads')\n",
    "history = model.keras_model.history.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0c784f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f23ecbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6cfd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
